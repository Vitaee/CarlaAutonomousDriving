# ğŸš— Enhanced CARLA Training Pipeline Guide

## Overview
This guide shows how to train the `ProductionCarlaModel` with your enhanced dataset collection for autonomous driving.

## ğŸ¯ **Training Pipeline Summary**

### **What's New:**
- âœ… **Multi-Modal Learning**: 3 Cameras + LiDAR point clouds
- âœ… **Temporal Sequences**: 5 consecutive frames for LSTM processing  
- âœ… **Multi-Task Learning**: Steering + Speed + Emergency Brake prediction
- âœ… **Safety Components**: Uncertainty estimation + Anomaly detection
- âœ… **Advanced Architecture**: EfficientNet-B7 + Attention + LSTM

### **Target Dataset:**
- ğŸ“Š **40,000 frames total** (8,000 temporal sequences)
- ğŸŒ **Town02 + Town03** data collection
- ğŸŒ¦ï¸ **7 weather conditions** per town
- ğŸš¨ **Emergency brake scenarios** included

---

## ğŸ“‹ **Step-by-Step Training Process**

### **Step 1: Data Collection**

First, collect data from both towns (you mentioned you're doing this):

```bash
# Collect Town02 data (modify the script to set map='Town02')
python dataset_collect_in_carla.py

# Collect Town03 data (modify the script to set map='Town03') 
python dataset_collect_in_carla.py
```

**Expected Output Structure:**
```
data_real/
â”œâ”€â”€ dataset_carla_enhanced_Town02/
â”‚   â”œâ”€â”€ sequence_000001/
â”‚   â”‚   â”œâ”€â”€ images_center/ (center_00.png to center_04.png)
â”‚   â”‚   â”œâ”€â”€ images_left/   (left_00.png to left_04.png)
â”‚   â”‚   â”œâ”€â”€ images_right/  (right_00.png to right_04.png)
â”‚   â”‚   â”œâ”€â”€ lidar/         (lidar_00.npy to lidar_04.npy)
â”‚   â”‚   â””â”€â”€ metadata.json
â”‚   â”œâ”€â”€ sequence_000002/
â”‚   â””â”€â”€ ... (4000 sequences for 20k frames)
â””â”€â”€ dataset_carla_enhanced_Town03/
    â”œâ”€â”€ sequence_000001/
    â””â”€â”€ ... (4000 sequences for 20k frames)
```

### **Step 2: Verify Dataset**

Test your enhanced dataset:

```bash
python test_enhanced_dataset.py
```

**Expected Output:**
```
âœ… Dataset loaded successfully!
   Total sequences: 4000 (per town)
âœ… DataLoader created successfully!
âœ… Model forward pass successful!
ğŸ‰ All tests passed! Your enhanced dataset is ready for training.
```

### **Step 3: Start Training**

#### **Option A: Quick Test (Recommended First)**
```bash
python start_enhanced_training.py --quick
```
- Runs for 10 epochs to verify everything works
- Uses batch_size=4, optimized for temporal sequences

#### **Option B: Full Training**
```bash
python start_enhanced_training.py --full
```
- Runs for 200 epochs for production model
- Full multi-task learning with all safety components

#### **Option C: Custom Training**
```bash
python start_enhanced_training.py \
    --batch_size 4 \
    --epochs 100 \
    --learning_rate 1e-4 \
    --run_name "my_enhanced_model"
```

---

## ğŸ”§ **Training Configuration**

### **Updated Config Settings** (`config.py`):
```python
# Enhanced dataset settings
dataset_type: str = "enhanced"
sequence_length: int = 5  # Temporal frames
image_size: tuple = (224, 224)  # EfficientNet-B7
max_lidar_points: int = 2000

# Training settings
batch_size: int = 4  # Smaller due to temporal sequences
epochs_count: int = 100
learning_rate: float = 1e-4  # Lower for fine-tuning

# Multi-task loss weights
steering_loss_weight: float = 2.0  # Primary task
speed_loss_weight: float = 1.0     # Secondary task
brake_loss_weight: float = 1.5     # Safety critical
uncertainty_loss_weight: float = 0.5
anomaly_loss_weight: float = 0.3
```

### **Model Architecture** (`ProductionCarlaModel`):
```python
# Input: Multi-modal temporal sequences
center_imgs: (B, 5, 3, 224, 224)    # Center camera sequence
left_imgs: (B, 5, 3, 224, 224)      # Left camera sequence  
right_imgs: (B, 5, 3, 224, 224)     # Right camera sequence
lidar_points: (B, 5, 2000, 3)       # LiDAR point clouds

# Output: Multi-task predictions
steering: (B, 1)           # Primary steering prediction
speed: (B, 1)              # Speed estimation
emergency_brake: (B, 2)    # Emergency brake classifier
uncertainty: (B, 1)        # Epistemic uncertainty
anomaly_score: (B, 1)      # Anomaly detection score
```

---

## ğŸ“Š **Monitoring Training**

### **TensorBoard Visualization:**
```bash
tensorboard --logdir logs/enhanced_carla_town02_town03
```

**Metrics to Monitor:**
- ğŸ“ˆ **Loss/Total**: Overall multi-task loss
- ğŸ¯ **Loss/Steering**: Primary steering task
- âš¡ **Loss/Speed**: Speed prediction task  
- ğŸš¨ **Loss/Brake**: Emergency brake classification
- ğŸ›¡ï¸ **Safety/High_Uncertainty_Rate**: Safety metric
- ğŸ” **Safety/High_Anomaly_Rate**: Anomaly detection

### **Training Logs:**
```
INFO - Train - Total: 0.2547, Steer: 0.0123, Speed: 0.0089, Brake: 0.1567
INFO - Val   - Total: 0.2234, Steer: 0.0156, Speed: 0.0078, Brake: 0.1345
INFO - Safety - Uncertainty: 0.023, Anomaly: 0.012
INFO - New best model saved: 0.2234
```

---

## ğŸ’¾ **Model Checkpoints**

### **Saved Files:**
```
checkpoints/
â”œâ”€â”€ enhanced_carla_town02_town03_best.pt     # Best validation loss
â”œâ”€â”€ enhanced_carla_town02_town03_final.pt    # Final model
â”œâ”€â”€ enhanced_carla_town02_town03_epoch_10.pt # Every 10 epochs
â””â”€â”€ enhanced_carla_town02_town03_epoch_20.pt
```

### **Resume Training:**
```bash
python start_enhanced_training.py --resume checkpoints/enhanced_carla_town02_town03_epoch_50.pt
```

---

## ğŸ¯ **Expected Training Results**

### **With 40K Frames (8K Sequences):**
- ğŸ¯ **Training Time**: ~20-30 hours (GPU dependent)
- ğŸ“Š **Model Size**: ~101M parameters  
- ğŸ® **Memory Usage**: ~8-12GB GPU memory
- ğŸ“ˆ **Expected Performance**: 
  - Steering MSE: < 0.01
  - Speed MSE: < 0.05  
  - Emergency Brake Accuracy: > 95%
  - Uncertainty Calibration: Well-calibrated safety estimates

### **Performance Improvements:**
- âœ… **Better Generalization**: Multi-town training
- âœ… **Weather Robustness**: 7 weather conditions
- âœ… **Safety Awareness**: Uncertainty + anomaly detection
- âœ… **Temporal Consistency**: LSTM-based temporal modeling
- âœ… **Multi-Modal Understanding**: Camera + LiDAR fusion

---

## ğŸš€ **Quick Start Commands**

1. **Test Dataset:**
   ```bash
   python test_enhanced_dataset.py
   ```

2. **Quick Training Test:**
   ```bash
   python start_enhanced_training.py --quick
   ```

3. **Full Production Training:**
   ```bash
   python start_enhanced_training.py --full
   ```

4. **Monitor Progress:**
   ```bash
   tensorboard --logdir logs/
   ```

---

## ğŸ‰ **Success Indicators**

Your training is successful when you see:
- âœ… All dataset tests pass
- âœ… Training loss decreases smoothly
- âœ… Validation loss follows training loss (no overfitting)
- âœ… Safety metrics (uncertainty/anomaly) are reasonable
- âœ… Multi-task losses are balanced
- âœ… TensorBoard shows clear learning curves

## ğŸ› ï¸ **Troubleshooting**

### **Common Issues:**
1. **Out of Memory**: Reduce `batch_size` to 2 or 1
2. **Slow Loading**: Reduce `num_workers` 
3. **Dataset Not Found**: Check `data_real/` directory structure
4. **CUDA Errors**: Ensure PyTorch CUDA compatibility

### **Performance Optimization:**
- Use `--num_workers 8` for fast data loading
- Enable `pin_memory=True` (already configured)
- Use mixed precision training if needed
- Monitor GPU utilization with `nvidia-smi`

---

Your enhanced training pipeline is ready! ğŸš—ğŸ¤– The combination of multi-modal data, temporal sequences, and safety-aware architecture will create a production-ready autonomous driving model. 